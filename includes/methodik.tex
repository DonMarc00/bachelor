\chapter{Methodik}
Das folgende Kapitel hat es zum Ziel, den experimentellen Ansatz und die Methodik dieser Arbeit zu beschreiben. Es soll deutlich werden, wie die Forschungsfrage beantwortet wird und welche Schritte dafür notwendig sind. Zunächst werden die zu untersuchenden Modelle aufgelistet. Folgend wird die Anwendung der Forschungsmethode und die entsprechenden Metriken erklärt. Anschließend werden der Aufbau der Testumgebung und die verwendeten Datensätze beschrieben. 
\section{Auswahl der zu untersuchenden Modelle}
Zunächst gilt es die zu untersuchenden Modelle auszuwählen. Die Auswahl der Modelle erfolgt auf Basis der Forschungsfrage und der Zielsetzung dieser Arbeit. Es sollen Modelle untersucht werden, die im Bereich des \ac{VDU} eingesetzt werden können. Die Modelle sollen in der Lage sein, visuelle und textuelle Elemente in Dokumenten zu interpretieren. 

\textbf{Donut:} Das zentrale Modell dieser Arbeit ist \ac{Donut}, gegen welches die OCR-basierten Modelle als Vergleichs- bzw. Referenzmodelle herangezogen werden. Diese Herangehensweise ermöglicht es, die Stärken, Schwächen und Besonderheiten von Donut im Vergleich zu alternativen Methoden des \ac{VDU} zu identifizieren. Es gibt zwar jüngere Nachfolger von \ac{Donut}, jedoch wird in dieser Arbeit ausschließlich Donut untersucht, da es das erste Modell seiner Art ist und die Grundlage für die nachfolgenden Modelle bildet. Es ist in dieser Hinsicht schon etablierter als bspw. \ac{DUBLIN}. Ferner gibt es bereits mehr Forschungsergebnisse zu \ac{Donut} als zu jüngeren Modellen und die Verfügbarkeit von Open-Source Implementierungen ist gegeben.

\textbf{BERT:} \ac{BERT} ist ein rein textbasiertes Modell, welches in der natürlichen Sprachverarbeitung eingesetzt wird. In der Literatur wird es im Bereich des \ac{VDU} einer OCR häufig nachgelagert, um Ergebnisse zu verbessern. \footcites[Vgl. dazu ausführlich][]{nguyen_neural_2020}[Vgl. dazu ausführlich][]{jiang_evaluating_2021} Noch heute wird \ac{BERT} in vielen Forschungen als Vergleichsmodell herangezogen. Eine Eigenschaft, die jedoch beachtet werden muss, ist, dass \ac{BERT} nicht in der Lage ist, visuelle Elemente zu interpretieren. Es handelt sich lediglich um einen Encoder-basierten Transformer, der um keine layoutbasierten Informationen angereichert wurde, \footcites[Vgl. dazu ausführlich][]{devlin_bert_2018} anders als bspw. LayoutLMv3. Es werden in dieser Arbeit die Ergebnisse von \ac{BERT} zu \ac{Donut} im Rahmen der Namend Entity Recognition und der Informationsextraktion verglichen.

%TODO: Fußnote für die Lizenzbedingung anpassen
\textbf{LayoutLMv3:} LayoutLMv3 ist ein performantes und etabliertes OCR-abhängiges Modell. LayoutLM wurde stetig optimiert, bis es Version 3 erreichte. Im FUNSD-Benchmark schneidet es deutlich besser ab als Donut und auch im CORD-Benchmark sind die Ergebnisse besser. \footcites[Vgl. dazu ausführlich][]{huang_layoutlmv3_2022} Der Source-Code von LayoutLMv3 ist zwar einsehbar, jedoch ist das Modell nicht Open-Source. LayoutLMv3 unterliegt strengen Lizenzbedingungen\footcites[Vgl.][]{noauthor_microsoftlayoutlmv3-base_2023} und darf nur für nicht-kommerzielle Zwecke wie Forschung verwendet werden. Daher impliziert der Vergleich von LayoutLMv3 zu Donut mehrere Punkte. Zum einen wird eine Implikation hinsichtlich der Gegenüberstellung von Open-Source und proprietären Modellen gezogen. Zum anderen wird untersucht, ob die proprietäre Implementierung von LayoutLMv3 einen Vorteil gegenüber Donut bringt. Nicht zuletzt wird untersucht, wie OCR-freie Modelle gegenüber OCR-abhängigen Modellen in einer heterogenen, produktionsähnlichen Landschaft an Daten abschneiden.

\section{Metriken des Experiments}
Zuzüglich zu den Modellen, die untersucht werden, ist es notwendig, die Leistungsfähigkeit der Modelle anhand von Metriken zu bewerten. Die Metriken sollen die Effizienz und Genauigkeit der Modelle messen. Sie sollen es ermöglichen, die Modelle miteinander zu vergleichen und die Forschungsfrage bzw. die noch folgenden Hypothesen zu beantworten. Die Metriken, die in dieser Arbeit verwendet werden, sind: Accuracy, F1-Score und \ac{GPUh}. In den folgenden Passagen werden die Metriken und ihre Bedeutung erläutert. Zunächst ist es wichtig, die grundlegende Terminologie zu erläutern, um anschließend die jeweiligen Metriken unter Zunahme der Terminologie erklären zu können. Die Bezeichnungen \emph{positive Klasse} und \emph{negative Klasse} beziehen sich auf die Klassen, wie sie in einer Konfusionsmatrix definiert sind. Die positive Klasse ist die Klasse, die identifiziert werden soll, die negative Klasse ist die Klasse, die nicht identifiziert werden soll. In dieser Arbeit beschreibt \ac{TP} eine Information, die extrahiert wurde und tatsächlich im Dokument vorhanden ist. Ein \ac{TN} liegt vor, wenn eine bestimmte Information oder Entität, wie beispielsweise die Rechnungsnummer, im Dokument nicht vorhanden ist und vom Modell auch nicht extrahiert wurde. Ein \ac{FP} tritt auf, wenn das Modell eine Information oder Entität fälschlicherweise extrahiert, die tatsächlich nicht im Dokument vorhanden ist, oder wenn es eine Information falsch zuordnet, wie zum Beispiel die Fehlinterpretation einer IBAN als Rechnungsnummer. Ein \ac{FN} beschreibt eine Situation, in der eine im Dokument vorhandene und relevante Information, wie die Rechnungsnummer, vom Modell nicht erkannt oder extrahiert wurde. Diese Kategorisierung hilft, die Genauigkeit der Entitätsextraktion zu bewerten, indem sie nicht nur das Vorhandensein, sondern auch die korrekte Identifikation und Zuordnung der Entitäten berücksichtigt.\footcites[Vgl.][]{pawan_confusion_2019}

\textbf{Accuracy:} Die Accuracy ist eine Standardmetrik, die den Anteil der korrekt identifizierten Fälle (sowohl positiv als auch negativ) im Verhältnis zur Gesamtzahl aller Fälle misst. Sie bietet einen schnellen Überblick über die Effektivität eines Modells. Allerdings kann sie in Situationen mit ungleichen Klassenverteilungen irreführend sein, da sie die Effektivität in den einzelnen Klassen nicht differenziert betrachtet. Zusammen mit allen weiteren Metriken befinden sich die Werte zwischen 0 und 1. Ein hoher Wert für die Accuracy zeigt an, dass ein großer Anteil der gesamten Vorhersagen des Modells korrekt ist, sowohl positive als auch negative Vorhersagen. Sie ist besonders aussagekräftig, wenn die Klassen im Datensatz ausgewogen sind.
Ein niedriger Wert für die Accuracy deutet darauf hin, dass das Modell viele Fehler macht, was auf Probleme mit der Modellierung, der Datenqualität oder einer Klassenimbalance hindeuten kann.\footcites[Vgl.][S. 508]{naser_error_2023}
\begin{equation}
    {Accuracy} = \frac{TP + TN}{TP + TN + FP + FN} 
\end{equation}


\textbf{F1-Score:} Der F1-Score ist ein harmonisches Mittel aus Präzision und Recall, das heißt, er berücksichtigt sowohl die Fähigkeit des Modells, relevante Informationen korrekt zu identifizieren (Präzision), als auch die Fähigkeit, alle relevanten Informationen zu erfassen (Recall). Ein niedriger F1-Score weist auf eine oder mehrere der folgenden Situationen hin: Das Modell kann relevante Informationen nicht korrekt identifizieren, es kann relevante Informationen nicht vollständig erfassen oder es kann irrelevante Informationen nicht ausschließen. In jedem Fall führt ein niedriger F1-Score zu einer geringeren Genauigkeit der Informationsgewinnung, was wiederum zu einer ineffizienten und ungenauen Dokumentenverarbeitung führt.

\begin{itemize}
    \item Precision (Präzision) misst den Anteil der korrekt identifizierten positiven Fälle im Verhältnis zu allen Fällen, die vom Modell als positiv eingestuft wurden. Eine hohe Precision bedeutet, dass ein hoher Anteil der positiven Vorhersagen des Modells tatsächlich korrekt ist, was bei Aufgaben wichtig ist, bei denen die Kosten für falsch positive Ergebnisse hoch sind.
    Eine niedrige Precision zeigt an, dass viele der als positiv klassifizierten Fälle falsch sind, was in Szenarien, in denen Vertrauen in das Ergebnis entscheidend ist, problematisch sein kann. \footcites[Vgl.][S. 508]{naser_error_2023}
    \begin{equation}
        Precision = \frac{TP}{TP + FP}
    \end{equation}
    \item Recall (Sensitivität) gibt den Anteil der korrekt identifizierten positiven Fälle im Verhältnis zu allen tatsächlich positiven Fällen an. Ein hoher Recall-Wert zeigt, dass das Modell einen großen Anteil der tatsächlich positiven Fälle korrekt erkennt und extrahiert. Dies ist wichtig in Situationen, wo das Übersehen von positiven Fällen schwerwiegende Folgen haben kann. Ein niedriger Recall bedeutet, dass das Modell viele tatsächliche positive Fälle nicht erkennt, was bei kritischen Anwendungen wie medizinischen Diagnosen oder Betrugserkennung zu ernsthaften Problemen führen kann. \footcites[Vgl.][S. 508]{naser_error_2023}
    \begin{equation}
        Recall = \frac{TP}{TP + FN}
    \end{equation}
\end{itemize}

Indem der F1-Score, Precision und Recall vereint, bietet er eine robuste Bewertung der Modellleistung, die sowohl die Vermeidung von Falsch-Positiven als auch die korrekte Identifikation aller positiven Fälle berücksichtigt. Ein hoher F1-Score ist ein Indikator dafür, dass das Modell sowohl eine hohe Precision als auch einen hohen Recall erreicht hat, was auf eine ausgewogene Leistung in Bezug auf die Vermeidung von falsch positiven und das Übersehen von tatsächlich positiven Fällen hindeutet.
Ein niedriger F1-Score zeigt, dass das Modell entweder viele relevante Fälle übersieht oder viele irrelevante Fälle fälschlicherweise als positiv einstuft, was auf eine schlechte Gesamtleistung des Modells hinweist.\footcites[Vgl.][S. 509]{naser_error_2023}
\begin{equation}
    F_{1} = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}
\end{equation}

\textbf{GPUh:} \ac{GPUh} beziehen sich auf die Rechenzeit, die für das Feintuning auf GPU-Hardware benötigt wird. Diese Metrik ist besonders relevant, um die Kosten der Modellentwicklung und -anwendung zu bewerten. Sie ist von großer Bedeutung für kleinere Organisationen oder Einzelpersonen, die möglicherweise nicht über die Ressourcen verfügen, um umfangreiche Datensätze für das Training eigener Modelle zu sammeln oder teure GPU-Ressourcen über längere Zeiträume zu nutzen.

\section{Forschungsdesign}
\subsection{Voraussetzungen für das Experiment}
Das Forschungsdesign dieser Arbeit basiert auf einem experimentellen Ansatz, der darauf abzielt, die Performance von KI-Modellen speziell im Bereich der Informationsextraktion aus Dokumenten, zu untersuchen und zu vergleichen. Dabei liegt der Fokus auf der Evaluation des Donut-Modells im Vergleich zu OCR-abhängigen Modellen wie LayoutLMv3 und BERT, insbesondere unter Produktivbedingungen, die über die Rahmenbedingungen standardisierter Benchmark-Datensätze hinausgehen.

In einem Experiment müssen diverse Voraussetzungen erfüllt werden. Das Untersuchungsobjekt sind im Fall dieser Arbeit die zuvor genannten KI-Modelle und deren Performance in der Informationsextraktion aus Dokumenten. Der Beobachter ist der Forscher, der die Modelle trainiert und evaluiert, sowie die Monitoring-Tools, welche für die Beobachtung des Aufwands der Genauigkeit der Modelle zuständig sind. Der Versuchsaufbau gestaltet sich wie folgt: Zunächst werden die Modelle auf den gleichen Trainingsdatensatz trainiert (Finetuning) und anschließend auf einem Testdatensatz evaluiert. Die Ergebnisse werden anhand der zuvor definierten Metriken gemessen und miteinander verglichen. Der Untersuchungsvorgang wird detailliert in Kapitel 4 beschrieben. Das Experiment wird durchgeführt, um diverse Hypothesen zu überprüfen.

Um Störfaktoren zu minimieren werden identische Daten für Training, Validierung und Test genutzt. Die Daten werden entsprechend vorbereitet, um ein Vermischen von Daten zu vermeiden. Zudem wird auf die Konfiguration von Tokenizern und neuronalen Netzen geachtet, um konsistente Embeddings zu generieren.

Die relevanten Variablen für das Experiment lauten wie folgt:
\begin{itemize}
    \item \textbf{Unabhängige Variablen:} Die unabhängigen Variablen sind die Menge der verwendeten Trainingsdaten, die Hyperparameter der Modelle und die Architektur der Modelle
    \item \textbf{Abhängige Variablen:} Die Performance des Modells, gemessen anhand der Metriken Accuracy, F1-Score und GPUh
\end{itemize}

\subsection{Durchführung des Experiments}
Es werden drei Hypothesen überprüft, die sich auf die Leistungsfähigkeit von Donut im Vergleich zu OCR-abhängigen Modellen beziehen. Die Hypothesen lauten wie folgt:
\begin{itemize}
    \item \textbf{Hypothese 1:} Eine höhere Menge an Daten verbessert die Performance der Modelle, wobei eine abflachende oder sogar abfallende Wirkung bei Overfitting zu beobachten ist.
    \item \textbf{Hypothese 2:} Bei heterogenen Daten erzielt Donut bessere Ergebnisse als LayoutLMv3 und BERT.
    \item \textbf{Hypothese 3:} Die Qualität der vorgelagerten OCR beeinflusst die Ergebnisse von LayoutLMv3 und BERT signifikant.
\end{itemize}

Um die Begriffe der Forschungsfrage und der Hypothesen messbar zu machen, wird durch die Auswahl spezifischer Metriken wie F1-Score, Accuracy und \ac{GPUh} eine klare Messbarkeit der Variablen gewährleistet. Aufgrund der Begrenztheit verfügbarer Daten fungiert der vorhandene Datensatz als Stichprobe. Um die Konsistenz zu gewährleisten, bleibt dieser Datensatz für alle Phasen des Experiments gleich. Es wird höchstens getestet, wie die Modelle abschneiden, wenn lediglich ein Teil des Datensatzes genutzt wird. Dieser Teil ist jedoch für alle Modelle gleich. 

Es werden diverse Vorkehrungen getroffen, um die Gütekriterien des Experiments sicherzustellen. Um eine hohe Validität zu gewährleisten, werden etablierte Metriken verwendet, die die Performance der Modelle objektiv messen. Die Erfassung der \ac{GPUh} erfolgt durch Monitoring-Tools, die die Rechenzeit auf GPU-Hardware messen, um Konsistenz zu gewährleisten. Die Reliabilität (Zuverlässigkeit) wird durch die algorithmische Natur des Experiments gewährleistet. Die Ergebnisse werden dadurch reproduzierbar. Die Objektivität wird durch den Einsatz der Pipeline in Tests von verschiedenen unabhängigen Personen gefördert, die auf unterschiedlichen Rechenplattformen, einschließlich eigener Hardware und Cloud-Diensten, durchgeführt werden. Diese systematische Vorgehensweise ermöglicht eine gründliche Überprüfung der Leistungs- und Effizienzmerkmale des Donut-Modells im Vergleich zu anderen Modellen, wobei ein besonderes Augenmerk auf die praktische Anwendbarkeit und Realitätsnähe der Testbedingungen gelegt wird.

\section{Aufbau der Testumgebung}
Die Testumgebung für die Durchführung der Experimente zur Evaluation der Modellperformance ist sorgfältig ausgewählt und konfiguriert, um repräsentative und zuverlässige Ergebnisse zu gewährleisten. Diese Umgebung ist speziell darauf ausgerichtet, die Anforderungen anspruchsvoller KI-Modelle zu erfüllen und gleichzeitig die Bedingungen eines produktiven Einsatzes nachzuahmen.
% TODO: Anhangsnummern einfügen
Die Experimente werden auf einem leistungsfähigen Rechner durchgeführt, dessen Spezifikationen darauf abgestimmt sind, die rechenintensiven Prozesse des Trainings und des Feintunings der KI-Modelle effizient zu bewältigen. Diese umfassen Nvidia GPUs, welche die \ac{CUDA}-Plattform zum beschleunigten Training unterstützen. Die genauen Spezifikationen der GPU und aller weiteren Komponenten der Rechenmaschienen sind in Angang X aufgeführt. Die Spezifikationen der Cloud-Instanzen, die für die Experimente genutzt werden, sind ebenfalls in Anhang X aufgeführt.

Die für die Experimente verwendeten Datensätze stammen aus dem produktiven Umfeld des Unternehmens und unter anderem von Kunden. Um die Vielfalt realer Anwendungsfälle abzubilden, wird besonderer Wert darauf gelegt, dass die Daten heterogen bezüglich Layout und Text sind. Die Heterogenität der Daten soll sicherstellen, dass die Modelle unter realistischen und anspruchsvollen Bedingungen getestet werden.

Aufgrund der begrenzten Verfügbarkeit von annotierten Datensätzen werden die Daten teilweise mithilfe vom Azure Document Intelligence Studio annotiert. Es ist jedoch zu beachten, dass die Qualität der Annotationen eingeschränkt sein kann, was in späteren Kapiteln diskutiert wird. 

%TODO: Den Teil mit Konstantin nochmal besprechen
Um Datenschutzanforderungen gerecht zu werden und die Verwendung von Kundendaten zu ermöglichen, wird ein strenges Verfahren zur Anonymisierung der Daten angewendet. Dieses Verfahren entfernt oder ersetzt alle personenbezogenen Informationen und andere sensible Daten, um die Privatsphäre zu schützen, während die inhaltliche Integrität der Dokumente für die Zwecke des Experiments erhalten bleibt. Beispielsweise würde der Name des Kunden Max Mustermann durch ein Pseydonym wie Alex Müller ersetzt werden. 

Diese sorgfältige Konfiguration der Testumgebung und Auswahl der Datensätze gewährleistet, dass die Experimente unter Bedingungen durchgeführt werden, die die Anforderungen und Herausforderungen eines produktiven Einsatzes der KI-Modelle für die Dokumentenverarbeitung und -verständnis realistisch abbilden.