\chapter{Methodik}
Das folgende Kapitel hat es zum Ziel den experimentellen Ansatz und die Methodik dieser Arbeit zu beschreiben. Es soll deutlich werden, wie die Forschungsfrage beantwortet wird und welche Schritte dafür notwendig sind. Zunächst werden die zu untersuchenden Modelle aufgelistet. Folgend wird die Anwendung der Forschungsmethode und die entsprechenden Metriken erklärt. Anschließend wird der Aufbau der Testumgebung und die verwendeten Datensätze beschrieben. Es soll ein klares Bild geschaffen werden, mit welchen Mitteln die Forschungsfrage beantwortet wird.

\section{Auswahl der zu untersuchenden Modelle}
Zunächst gilt es die zu untersuchenden Modelle auszuwählen. Die Auswahl der Modelle erfolgt auf Basis der Forschungsfrage und der Zielsetzung dieser Arbeit. Es sollen Modelle untersucht werden, die im Bereich des \ac{VDU} eingesetzt werden können. Die Modelle sollen in der Lage sein, visuelle und textuelle Elemente in Dokumenten zu interpretieren. 

\textbf{Donut:} Das zentrale Modell dieser Arbeit ist \ac{Donut}, gegen welches die OCR-basierten Modelle als Vergleichs- bzw. Referenzmodelle herangezogen werden. Diese Herangehensweise ermöglicht es, die Stärken, Schwächen und Besonderheiten von Donut im Vergleich zu alternativen Methoden des \ac{VDU} zu identifizieren. Es gibt zwar jüngere nachfolger von \ac{Donut}, jedoch wird in dieser Arbeit ausschließlich Donut untersucht, da es das erste Modell seiner Art ist und die Grundlage für die nachfolgenden Modelle bildet. Es ist in dieser hinsicht schon etablierter als bspw. \ac{DUBLIN}. Ferner wurde bereits viel mehr an \ac{Donut} als an jüngeren Modellen und die Verfügbarkeit von Open-Source Implementierungen ist gegeben.

\textbf{BERT:} \ac{BERT} ist ein rein textbasiertes Modell, welches in der natürlichen Sprachverarbeitung eingesetzt wird. In der Literatur wird es im Bereich des \ac{VDU} einer OCR häufig nachgelagert, um Ergebnisse zu verbessern. \footcites[Vgl. dazu ausführlich][]{nguyen_neural_2020} \footcites[Vgl. dazu ausführlich][]{jiang_evaluating_2021} Noch heute wird \ac{BERT} in vielen Forschungen als Vergleichsmodell herangezogen. Eine Eigenschaft die jedoch beachtet werden muss ist, dass \ac{BERT} nicht in der Lage ist, visuelle Elemente zu interpretieren. Es handelt sich lediglich um einen Encoder-basierten Transformer der um keine layoutbasierten Informationen angereichert wurde, \footcites[Vgl. dazu ausführlich][]{devlin_bert_2018} anders als bspw. LayoutLMv3. Es wird in dieser Arbeit untersucht, wie sich \ac{BERT} im Vergleich zu Donut schlägt, wenn es um die Interpretation von Rechnungen seitens einer OCR-Engine geht. Die Ergebnisse werden von BERT lediglich verbessert.

\textbf{LayoutLMv3:} LayoutLMv3 ist ein performantes und etabliertes OCR-abhängiges Modell. LayoutLM wurde stetig optimiert bis es Version 3 erreichte. Im FUNSD-Benchmark schneidet es deutlich besser ab als Donut und auch im CORD-Benchmark sind die Ergebnisse besser. Der Source-Code von LayoutLMv3 ist zwar einsehbar, jedoch ist das Modell nicht Open-Source. LayoutLMv3 unterliegt strengen Lizenzbedingungen und darf nur für nicht-kommerzielle Zwecke wie Forschung verwendet werden. Daher impliziert der Vergleich von LayoutLMv3 zu Donut mehrere Punkte. Zum einen wird eine Implikation hinsichtlich der Gegenüberstellung von Open-Source und proprietären Modellen gezogen. Zum anderen wird untersucht, ob die proprietäre Implementierung von LayoutLMv3 einen Vorteil gegenüber Donut bringt. Nicht zuletzt wird untersucht, wie OCR-freie Modelle gegenüber OCR-abhängigen Modellen in einer heterogenen produktionsähnlichen Landschaft an Daten abschneiden.

\section{Metriken des Experiments}
Zuzüglich zu den Modellen, die untersucht werden, ist es notwendig, die Leistungsfähigkeit der Modelle anhand von Metriken zu bewerten. Die Metriken sollen die Effizienz und Genauigkeit der Modelle messen. Die Metriken sollen es ermöglichen, die Modelle miteinander zu vergleichen und die Forschungsfrage bzw. die noch folgenden Hypothesen zu beantworten. Die Metriken, die in dieser Arbeit verwendet werden, sind: Accuracy, F1-Score und \ac{GPUh}. Die folgenden Passagen erläutern die Metriken und deren Bedeutung. Die Bezeichnungen \emph{positive Klasse} und \emph{negative Klasse} beziehen sich auf die Klassen wie sie in einer Konfusionsmatrix definiert sind. Die positive Klasse ist die Klasse, die identifiziert werden soll, die negative Klasse ist die Klasse, die nicht identifiziert werden soll. In dieser Arbeit ist die echte positive Klasse eine Information die extrahiert wurde und tatsächlich im Dokument vorhanden ist. Die echte negative Klasse ist eine Information die nicht extrahiert wurde und nicht im Dokument vorhanden ist. Die falsch positive Klasse ist eine Information die extrahiert wurde, jedoch nicht im Dokument vorhanden ist. Die falsch negative Klasse ist eine Information die nicht extrahiert wurde, jedoch im Dokument vorhanden ist. \footcites[Vgl.][]{pawan_confusion_2019}(Braucht es hier eine Abbildung?)

\textbf{Accuracy:} Die Accuracy ist eine Standardmetrik, die den Anteil der korrekt identifizierten Fälle (sowohl positiv als auch negativ) im Verhältnis zur Gesamtzahl aller Fälle misst. Sie bietet einen schnellen Überblick über die Leistungsfähigkeit eines Modells. Allerdings kann sie in Situationen mit ungleichen Klassenverteilungen irreführend sein, da sie die Leistung in den einzelnen Klassen nicht differenziert betrachtet. \footcites[Vgl.][S. 508]{naser_error_2023}
\begin{equation}
    {Accuracy} = \frac{TP + TN}{TP + TN + FP + FN} \footnotemark
\end{equation}
\footnotetext{TP = True Positives, TN = True Negatives, FP = False Positives, FN = False Negatives}

\textbf{F1-Score:} Der F1-Score ist eine Metrik, die das harmonische Mittel aus Precision und Recall bildet. Er ist besonders geeignet für Situationen, in denen die Kosten für inkorrekt identifizierte Fälle hoch sind. Der F1-Score bietet ein ausgewogeneres Maß für die Leistung eines Modells, insbesondere wenn ein Ungleichgewicht zwischen den Klassen besteht.

\begin{itemize}
    \item Precision (Präzision) misst den Anteil der korrekt identifizierten positiven Fälle im Verhältnis zu allen Fällen, die vom Modell als positiv eingestuft wurden. Sie ist nützlich, wenn die Kosten für Falsch-Positive hoch sind. \footcites[Vgl.][S. 508]{naser_error_2023}
    \begin{equation}
        Precision = \frac{TP}{TP + FP}
    \end{equation}
    \item Recall (Sensitivität) gibt den Anteil der korrekt identifizierten positiven Fälle im Verhältnis zu allen tatsächlich positiven Fällen an. Er ist besonders relevant, wenn die Kosten für Falsch-Negative groß sind. \footcites[Vgl.][S. 508]{naser_error_2023}
    \begin{equation}
        Recall = \frac{TP}{TP + FN}
    \end{equation}
\end{itemize}

Indem der F1-Score Precision und Recall vereint, bietet er eine robuste Bewertung der Modellleistung, die sowohl die Vermeidung von Falsch-Positiven als auch die korrekte Identifikation aller positiven Fälle berücksichtigt. \footcites[Vgl.][S. 509]{naser_error_2023}
\begin{equation}
    F1-Score = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}
\end{equation}

\textbf{GPUh:} \ac{GPUh} beziehen sich auf die Rechenzeit, die für das Feintuning auf GPU-Hardware benötigt wird. Diese Metrik ist besonders relevant, um die Kosten der Modellentwicklung und -anwendung zu bewerten. Sie ist von großer Bedeutung für kleinere Organisationen oder Einzelpersonen, die möglicherweise nicht über die Ressourcen verfügen, um umfangreiche Datensätze für das Training eigener Modelle zu sammeln oder teure GPU-Ressourcen über längere Zeiträume zu nutzen.

\section{Forschungsdesign}
\subsection{Voraussetzungen für das Experiment}
Das Forschungsdesign dieser Arbeit basiert auf einem experimentellen Ansatz, der darauf abzielt, die Performance von KI-Modellen, speziell im Bereich der Informationsextraktion aus Dokumenten, zu untersuchen und zu vergleichen. Dabei liegt der Fokus auf der Evaluation des Donut-Modells im Vergleich zu OCR-abhängigen Modellen wie LayoutLMv3 und BERT, insbesondere unter Produktivbedingungen, die über die Rahmenbedingungen standardisierter Benchmark-Datensätze hinausgehen.

In einem Experiment müssen diverse Voraussetzungen erfüllt werden. Das Untersuchungsobjekt sind im Fall dieser Arbeit die zuvor genannten KI-Modelle und deren Performance in der Informationsextraktion aus Dokumenten. Der Beobachter ist der Forscher, der die Modelle trainiert und evaluiert, sowie die Monitoring-Tools für den Aufwand und die Genauigkeit der Modelle. Der Versuchsaufbau gestalltet sich wie folgt: Zunächst werden die Modelle auf den gleichen Datensätzen optimiert (Finetuning) und anschließend auf einem Testdatensatz evaluiert. Die Ergebnisse werden anhand der zuvor definierten Metriken gemessen und miteinander verglichen. Der Untersuchungsvorgang wird detailliert in Kapitel 4 beschrieben. Das Experiment wird durchgeführt um diverse Hypothesen zu überprüfen.

Um Störfaktoren zu minimieren werden identische Daten für Training, Validierung und Test genutzt. Die Daten werden entsprechend vorbereitet, um ein Vermischen von Daten zu vermeiden. Zudem wird auf die Konfiguration von Tokenizern und neuronalen Netzen geachtet, um konsistente Embeddings zu generieren.

Die relevanten Variablen für das Experiment lauten wie folgt (Darüber muss nochmal geredet werden):
\begin{itemize}
    \item \textbf{Unabhängige Variablen:} Die unabhängige Variablen sind die Menge der verwendeten Trainingsdaten, die Hyperparameter der Modelle und die Architektur der Modelle
    \item \textbf{Abhängige Variablen:} Die Performance des Modells, gemessen anhand der Metriken Accuracy, F1-Score und GPUh
\end{itemize}

\subsection{Durchführung des Experiments}
Es werden drei Hypothesen überprüft, die sich auf die Leistungsfähigkeit von Donut im Vergleich zu OCR-abhängigen Modellen beziehen. Die Hypothesen lauten wie folgt:
\begin{itemize}
    \item \textbf{Hypothese 1:} Eine höhere Menge an Daten verbessert die Performance der Modelle, wobei eine abflachende oder sogar abfallende Wirkung bei Overfitting zu beobachten ist.
    \item \textbf{Hypothese 2:} Bei heterogenen Daten erzielt Donut bessere Ergebnisse als LayoutLMv3 und BERT.
    \item \textbf{Hypothese 3:} Die Qualität der vorgelagerten OCR beeinflusst die Ergebnisse von LayoutLMv3 und BERT signifikant.
\end{itemize}

Um die Begriffe der Forschungsfrage und der Hypothesen zu operationalisieren wird durch die Auswahl spezifischer Metriken wie F1-Score, Accuracy und \ac{GPUh} eine klare Messbarkeit der Variablen gewährleistet. Aufgrund der Begrenztheit verfügbarer Daten fungiert der vorhandene Datensatz als Stichprobe. Um die Konsistenz zu gewährleisten, bleibt dieser Datensatz für alle Phasen des Experiments gleich. Es wird höchstens getestet wie die Modelle abschneiden, wenn lediglich ein Teil des Datensatzes genutzt wird. Dieser Teil ist jedoch für alle Modelle gleich. 

Es werden diverse Vorkehrungen getroffen um die Gütekriterien des Experiments sicherzustellen. Um eine hohe Validität zu gewährleisten, werden etablierte Metriken verwendet, die die Performance der Modelle objektiv messen. Die Erfassung der \ac{GPUh} erfolgt durch Monitoring-Tools, die die Rechenzeit auf GPU-Hardware messen, um Konsistenz zu gewährleisten. Die Reliabilität (Zuverlässigkeit) wird durch die algorithmische Natur des Experiments gewährleistet. Die Ergebnisse werden dadurch reproduzierbar. Da neuronale Netze nicht deterministisch sind und die Ergebnisse von Zufallsfaktoren abhängen, wird das Experiment mehrfach durchgeführt und die Ergebnisse gemittelt. Statistisches Rauschen wird als Teil der Analyse akzeptiert. Die Objektivität wird durch den Test der Pipeline durch mehrere Personen sochergestellt, einschließlich der Verwendung unterschiedlicher Rechenumgebungen wie eigene Hardware und Cloud-Dienste. Diese methodische Herangehensweise ermöglicht eine fundierte Untersuchung der Performance und Effizienz von Donut im Vergleich zu anderen Modellen, wobei besonderes Augenmerk auf die praktische Anwendbarkeit und Realitätsnähe der Testbedingungen gelegt wird.

\section{Aufbau der Testumgebung}
Die Testumgebung für die Durchführung der Experimente zur Evaluation der Modellperformance ist sorgfältig ausgewählt und konfiguriert, um repräsentative und zuverlässige Ergebnisse zu gewährleisten. Diese Umgebung ist speziell darauf ausgerichtet, die Anforderungen anspruchsvoller KI-Modelle zu erfüllen und gleichzeitig die Bedingungen eines produktiven Einsatzes nachzuahmen.
% TODO: Anhangsnummern einfügen
Die Experimente werden auf einem leistungsfähigen Rechner durchgeführt, dessen Spezifikationen darauf abgestimmt sind, die rechenintensiven Prozesse des Trainings und des Feintunings der KI-Modelle effizient zu bewältigen. Während die genauen Spezifikationen der GPU und weitere Details im Anhang der Arbeit dargelegt sind, umfasst die Maschine hochwertige Komponenten, die eine schnelle Verarbeitung und Analyse großer Datensätze ermöglichen. Zu diesen Komponenten gehören ein leistungsfähiger Prozessor, ausreichend RAM für die Datenverarbeitung und schnelle Speicherlösungen, um die I/O-Operationen zu optimieren. Die Spezifikationen der Cloud-Instanzen, die für die Experimente genutzt werden, sind ebenfalls im Anhang aufgeführt.

Die für die Experimente verwendeten Datensätze stammen aus dem produktiven Umfeld des Unternehmens und unter anderem von Kunden. Um die Vielfalt realer Anwendungsfälle abzubilden, wird besonderer Wert darauf gelegt, dass die Daten heterogen sind. Dies umfasst eine Vielfalt in Inhalten d.h. unterschiedliche Formate der Rechnungen. Die Heterogenität der Daten soll sicherstellen, dass die Modelle unter realistischen und anspruchsvollen Bedingungen getestet werden.

Aufgrund der begrenzten Verfügbarkeit von annotierten Datensätzen werden die Daten teilweise mithilfe von Azure-Diensten annotiert. Es ist jedoch zu beachten, dass die Qualität der Annotationen eingeschränkt sein kann, was in späteren Kapiteln diskutiert wird. Um eine hohe Ground-Truth-Qualität für die Testdaten zu gewährleisten, werden diese manuell annotiert. Die manuelle Annotation ist besonders wichtig, um die Validität der Testergebnisse zu sichern, da eine Verwendung von OCR-generierten Daten als Testdaten zu Verzerrungen führen könnte.

Um Datenschutzanforderungen gerecht zu werden und die Verwendung von Kundendaten zu ermöglichen, wird ein strenges Verfahren zur Anonymisierung der Daten angewendet. Dieses Verfahren entfernt oder ersetzt alle personenbezogenen Informationen und andere sensible Daten, um die Privatsphäre zu schützen, während die inhaltliche Integrität der Dokumente für die Zwecke des Experiments erhalten bleibt. Beispielsweise würde der Name des Kunden Max Mustermann durch ein Pseydonym wie Alex Müller ersetzt werden. 

Diese sorgfältige Konfiguration der Testumgebung und Auswahl der Datensätze gewährleistet, dass die Experimente unter Bedingungen durchgeführt werden, die die Anforderungen und Herausforderungen eines produktiven Einsatzes der KI-Modelle für die Dokumentenverarbeitung und -verständnis realistisch abbilden.