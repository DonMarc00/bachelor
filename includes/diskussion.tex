\chapter{Diskussion und kritische Betrachtung der Forschung}
In diesem Kapitel werden die in Kapitel 5 präsentierten Ergebnisse eingehend diskutiert, um tiefere Einblicke in die Implikationen der Forschungsergebnisse für praktische Anwendungen zu gewinnen. Dabei wird zunächst auf die Auswirkungen der Modellperformance auf Geschäftsprozesse und die potenziellen Anwendungsbereiche der untersuchten Modelle eingegangen. Dies umfasst sowohl die direkten Auswirkungen der Nutzung von Document Understanding Transformers in realen Unternehmenskontexten als auch die strategischen Überlegungen, die Unternehmen anstellen sollten, wenn sie erwägen, solche Technologien zu implementieren.

Des Weiteren werden die Limitationen der durchgeführten Studie kritisch reflektiert. Es wird diskutiert, inwiefern die gewählten Methoden, die Datensätze und die experimentellen Bedingungen möglicherweise zu Verzerrungen in den Ergebnissen geführt haben könnten. Diese Diskussion ist entscheidend, um die Validität und Reliabilität der Studienergebnisse zu verstehen und ihre Generalisierbarkeit einschätzen zu können.

Abschließend wird ein Ausblick für zukünftige Forschungsarbeiten gegeben. Es werden Empfehlungen ausgesprochen, welche Aspekte in folgenden Studien berücksichtigt werden sollten, um die Forschung im Bereich der automatisierten Dokumentenverarbeitung voranzutreiben. Diese Empfehlungen basieren auf den erkannten Forschungslücken und den während der Studie gewonnenen Erkenntnissen. Dabei wird insbesondere auf die Notwendigkeit eingegangen, weitere innovative Ansätze zu entwickeln, die die Limitationen bestehender Modelle überwinden können.

\section{Implikationen für die Praxis}
Wie bereits in Kapitel 5 erwähnt, erzielt Donut gute Ergebnisse, die aber nicht mit den Ergebnissen von OCR-basierten Modellen mithalten können. Von daher ist es fraglich, ob der Einsatz von Document Understanding Transformer Modellen in der vollständigen Automatisierung sinnvoll ist. Jedoch bietet der Donut Ansatz einige Vorteile, die in der Praxis genutzt werden können. Wie bereits erwähnt, kann Donut die manuelle Dokumentenverarbeitung deutlich effizienter gestalten, indem es eine große Anzahl von Entitäten in Dokumenten bereits im Vorhinein erkennt und lediglich c.a. 20 \% der Entitäten manuell überprüft werden müssen. Dies kann die Bearbeitungszeit von Dokumenten erheblich reduzieren und somit die Effizienz der Dokumentenverarbeitung steigern. Ein weiterer Vorteil ist, dass sowohl das Training als auch die Inferenz von Donut sehr schnell und kostengünstig sind. Unternehmen, welche die interne automatisiert Dokumentenverarbeitung einführen möchten, können von diesen Vorteilen profitieren. In der Endanwendung ELO enterprise wird bspw. eine serverseitige Extraktionskomponente verwendet, die zwar sehr genau ist, aber auch sehr teuer und rechenintensiv. Donut könnte hier eine kostengünstige und effiziente Alternative darstellen. Wenn der Anspruch an die Genauigkeit nicht so hoch ist, kann Donut eine gute Lösung sein. Des Weiteren hat Donut den Vorteil, dass das Model auf der Clientseite ausgeführt wird und somit keine Daten an Dritte weitergegeben werden. Dies kann für Unternehmen, die großen Wert auf Datenschutz legen, ein entscheidender Faktor sein. In der Inferenz ist Donut auch nicht von GPUs abhängig, sondern kann auf CPUs in kurzer Zeit Daten verarbeiten. 

In diesem Zusammenhang ist anzumerken, dass die Donut-Pipeline so aufbereitet wurde, dass sie mit wenig Anpassungsaufwand in die Endanwendung integriert werden kann. Dies ist nicht Teil dieser Arbeit, da zu diesem Zeitpunkt noch nicht feststeht, ob Donut in der Endanwendung ELO enterprise integriert wird. Im Falle der Implementierung liefert Donut in der Inferenz die extrahierten Entitäten an die Endanwendung als JSON, welche diese dann weiterverarbeiten kann. Die Donut-Komponente kann in diesem Fall auch auf der Clientseite ausgeführt werden und benötigt keine zusätzlichen Ressourcen auf dem Server oder eine entsprechende Schnittstelle.

Ein weiterer wichtiger Punkt in der Praxis sind die Trainingsdaten und ihre Verfügbarkeit. Die meisten Unternehmen werden nicht über ausreichend annotierte Trainingsdaten verfügen, um ein Modell wie Donut zu trainieren. In diesem Fall kann auf Transfer Learning zurückgegriffen werden. Donut kann auf einem allgemeinen Datensatz wie FUNSD oder CORD vortrainiert werden und anschließend auf den Unternehmensdaten feinabgestimmt werden. Dies kann die Anforderungen an die Trainingsdaten erheblich reduzieren und den Implementierungsaufwand verringern. Dieser Ansatz wurde auch in dieser Arbeit gewählt. Allerdings kann es für Unternehmen schwierig sein, selbst einen kleinen Datensatz für das Finetuning zu annotieren. In diesem Fall kann auf externe Anbieter zurückgegriffen werden, die die Annotationen durchführen. Hier muss eine Abwägung zwischen Kosten der Annotation von externen Anbietern und der händischen Annotation durch Mitarbeiter getroffen werden. Des weiteren muss definiert werden, wie hoch der Anspruch an die Genauigkeit der Annotationen ist. Externe Annotationstools wie das Azure Document Intelligence Studio können zwar günstiger sein, liefern aber auch oft ungenauere Annotationen.

Die Diskussion über Trainingsdaten aus kommerzieller Sicht ist besonders relevant, da die Qualität und Verfügbarkeit von annotierten Daten oft die größte Hürde für die Implementierung fortgeschrittener maschineller Lernmodelle in Unternehmen darstellt. Die Anschaffung qualitativ hochwertiger, spezifisch annotierter Daten kann sehr kostspielig sein, insbesondere wenn es um seltene oder spezielle Dokumententypen geht, die für bestimmte Geschäftsanwendungen erforderlich sind. Unternehmen müssen daher die Kosten für die Datensammlung und -annotation gegen den erwarteten Nutzen abwägen.

Ein wichtiger Aspekt ist, dass die Investition in qualitativ hochwertige Trainingsdaten eine langfristige Investition in die Automatisierung und Effizienzsteigerung darstellen kann. Hochwertige Daten verbessern nicht nur die Leistung der Modelle, sondern verringern auch das Risiko von Fehlinterpretationen und Fehlern in der automatisierten Verarbeitung, was wiederum die Notwendigkeit manueller Eingriffe reduziert und die Gesamtzuverlässigkeit der Systeme erhöht. Unternehmen, die in der Lage sind, in diese Anfangsinvestitionen zu investieren, könnten eine schnellere Amortisierung und höhere Renditen in Form von Effizienzsteigerungen sehen.

Zusätzlich zur Eigenproduktion von Trainingsdaten kann die Nutzung von syntaktisch generierten oder semi-synthetischen Daten eine kosteneffiziente Alternative bieten. Durch Techniken wie Data Augmentation können bestehende Datensätze erweitert werden, um die Robustheit und Generalisierungsfähigkeit der Modelle zu verbessern, ohne die Kosten für die manuelle Annotation neuer Daten tragen zu müssen. Dies kann besonders nützlich sein, um Modelle gegenüber speziellen Szenarien zu stärken, die in den ursprünglichen Trainingsdaten unterrepräsentiert sind.